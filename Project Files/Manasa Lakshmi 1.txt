1. Dataset: Rice Image Dataset (75,000 images)
Download from Kaggle: https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset.
It contains five classes (Arborio, Basmati, Ipsala, Jasmine, Karacadag), each with 15,000 single-grain images 
reddit.com
+15
github.com
+15
github.com
+15
.

To download via Kaggle API:

bash
Copy
Edit
pip install kaggle
kaggle datasets download -d muratkokludataset/rice-image-dataset
unzip rice-image-dataset.zip -d rice_dataset/
2. Python Code: Transfer Learning with TensorFlow/Keras
Here's a concise notebook setup you can expand on:

python
Copy
Edit
import os
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Paths
DATA_DIR = 'rice_dataset'
IMG_SIZE = (224, 224)
BATCH = 32

# Data pipeline
train_gen = ImageDataGenerator(rescale=1./255,
                               validation_split=0.2,
                               rotation_range=20,
                               zoom_range=0.15,
                               horizontal_flip=True)

train_ds = train_gen.flow_from_directory(DATA_DIR,
                                         target_size=IMG_SIZE,
                                         batch_size=BATCH,
                                         subset='training',
                                         class_mode='categorical')

val_ds = train_gen.flow_from_directory(DATA_DIR,
                                       target_size=IMG_SIZE,
                                       batch_size=BATCH,
                                       subset='validation',
                                       class_mode='categorical')

# Model setup
base = MobileNetV2(input_shape=IMG_SIZE + (3,),
                   include_top=False,
                   weights='imagenet')
base.trainable = False

model = models.Sequential([
    base,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.3),
    layers.Dense(5, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train & fineâ€‘tune
history = model.fit(train_ds, epochs=5, validation_data=val_ds)

# Optionally unfreeze some layers and fine-tune further:
base.trainable = True
for layer in base.layers[:-20]:
    layer.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
history_fine = model.fit(train_ds, epochs=5, validation_data=val_ds)
model.save('grainpalette_mobilenetv2.h5')